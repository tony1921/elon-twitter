#!/usr/bin/env python3
"""
å¤„ç†å†å²æ•°æ®ï¼Œç”Ÿæˆæ¯æ—¥ç»Ÿè®¡
"""

import json
from datetime import datetime
from collections import OrderedDict

def process_historical_data():
    """å¤„ç†å†å²æ•°æ®"""

    print("=" * 70)
    print("  ğŸ“Š å¤„ç†å†å²æ•°æ®")
    print("=" * 70)

    # è¯»å–åŸå§‹æ•°æ®
    with open('data/raw_historical.json', 'r') as f:
        raw_data = json.load(f)

    if not raw_data.get('data'):
        print("âŒ æ— æ•°æ®")
        return

    posts = raw_data['data']
    print(f"\nğŸ“ æ€»æ¨æ–‡æ•°: {len(posts)}")

    # æŒ‰æ—¥æœŸç»Ÿè®¡
    daily_counts = OrderedDict()
    daily_details = {}

    for post in posts:
        created_at = post.get('createdAt', '')
        if created_at:
            date = created_at.split('T')[0]
            daily_counts[date] = daily_counts.get(date, 0) + 1

            # ä¿å­˜è¯¦æƒ…
            if date not in daily_details:
                daily_details[date] = []
            daily_details[date].append({
                'id': post.get('platformId'),
                'time': created_at.split('T')[1][:5],
                'content': post.get('content', '')[:50]
            })

    # æŒ‰æ—¥æœŸæ’åº
    daily_counts = OrderedDict(sorted(daily_counts.items()))

    print(f"ğŸ“… å¤©æ•°: {len(daily_counts)}")
    print(f"ğŸ“… æœ€æ—©: {list(daily_counts.keys())[0]}")
    print(f"ğŸ“… æœ€æ™š: {list(daily_counts.keys())[-1]}")

    # ç”Ÿæˆæ¯æ—¥è®°å½•æ ¼å¼
    daily_records = []
    for date, count in daily_counts.items():
        record = {
            "date": date,
            "count": count,
            "source": "xtracker_historical",
            "details_count": len(daily_details.get(date, [])),
            "created_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        daily_records.append(record)

    # ä¿å­˜æ¯æ—¥æ•°æ®
    with open('data/daily_tweets.json', 'w') as f:
        json.dump(daily_records, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ¯æ—¥æ•°æ®å·²ä¿å­˜åˆ°: data/daily_tweets.json")

    # æ˜¾ç¤ºç»Ÿè®¡
    print(f"\nğŸ“Š æ¯æ—¥æ¨æ–‡ç»Ÿè®¡ (æœ€è¿‘10å¤©):")
    print("=" * 70)

    for record in daily_records[-10:]:
        date = record['date']
        count = record['count']
        print(f"  {date}: {count:3d} æ¡")

    # æ€»ä½“ç»Ÿè®¡
    counts = [r['count'] for r in daily_records]
    print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
    print(f"  å¹³å‡: {sum(counts) / len(counts):.1f} æ¡/å¤©")
    print(f"  æœ€é«˜: {max(counts)} æ¡")
    print(f"  æœ€ä½: {min(counts)} æ¡")
    print(f"  æ€»è®¡: {sum(counts)} æ¡")

    # æŸ¥æ‰¾æœ€é«˜å’Œæœ€ä½çš„æ—¥æœŸ
    max_date = max(daily_counts, key=daily_counts.get)
    min_date = min(daily_counts, key=daily_counts.get)
    print(f"  æœ€å¤š: {max_date} ({daily_counts[max_date]} æ¡)")
    print(f"  æœ€å°‘: {min_date} ({daily_counts[min_date]} æ¡)")

    print("=" * 70)

    return daily_records


if __name__ == "__main__":
    process_historical_data()
