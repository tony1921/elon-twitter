#!/usr/bin/env python3
"""
æ£€æŸ¥XTrackeræ˜¯å¦æœ‰å†å²æ•°æ®
"""

from playwright.sync_api import sync_playwright
import re

def check_xtracker_history():
    """æ£€æŸ¥XTrackeræ˜¯å¦æœ‰å†å²æ•°æ®"""

    try:
        with sync_playwright() as p:
            print("=" * 70)
            print("  ğŸ” æ£€æŸ¥ XTracker å†å²æ•°æ®")
            print("=" * 70)

            browser = p.chromium.launch(headless=False)  # ä½¿ç”¨æœ‰ç•Œé¢æ¨¡å¼ï¼Œæ–¹ä¾¿è§‚å¯Ÿ
            page = browser.new_page()

            print("\nğŸ“¡ è®¿é—® XTracker...")
            page.goto('https://xtracker.polymarket.com', timeout=30000)

            # ç­‰å¾…é¡µé¢åŠ è½½
            page.wait_for_timeout(5000)

            # æŸ¥æ‰¾å¯èƒ½çš„é“¾æ¥å’ŒæŒ‰é’®
            print("\nğŸ” æŸ¥æ‰¾å†å²æ•°æ®ç›¸å…³å…ƒç´ ...")

            # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥
            links = page.query_selector_all('a')
            print(f"\n  æ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥:")

            history_keywords = ['history', 'past', 'archive', 'previous', 'stats', 'data', 'chart', 'graph']

            for link in links[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
                try:
                    text = link.inner_text().strip()
                    href = link.get_attribute('href')
                    if text:
                        print(f"    - {text[:50]} -> {href}")
                except:
                    pass

            # æŸ¥æ‰¾å¯èƒ½åŒ…å«å†å²æ•°æ®çš„å…ƒç´ 
            print("\nğŸ” æŸ¥æ‰¾æ•°æ®å…ƒç´ ...")

            # å°è¯•æŸ¥æ‰¾å›¾è¡¨ã€è¡¨æ ¼ç­‰
            selectors = [
                '[class*="chart"]',
                '[class*="graph"]',
                '[class*="history"]',
                '[class*="stats"]',
                'table',
                '[role="table"]',
            ]

            for selector in selectors:
                elements = page.query_selector_all(selector)
                if elements:
                    print(f"\n  æ‰¾åˆ° {len(elements)} ä¸ª '{selector}' å…ƒç´ ")
                    for el in elements[:3]:
                        try:
                            text = el.inner_text()[:100]
                            print(f"    å†…å®¹: {text}")
                        except:
                            pass

            # æ£€æŸ¥é¡µé¢æºä»£ç ä¸­æ˜¯å¦æœ‰APIç«¯ç‚¹
            print("\nğŸ” æ£€æŸ¥ç½‘ç»œè¯·æ±‚...")
            html = page.content()

            # æŸ¥æ‰¾å¯èƒ½çš„API
            api_patterns = [
                r'https://[^\s"\']*api[^\s"\']*',
                r'https://[^\s"\']*history[^\s"\']*',
                r'https://[^\s"\']*stats[^\s"\']*',
            ]

            for pattern in api_patterns:
                matches = re.findall(pattern, html)
                if matches:
                    print(f"  æ‰¾åˆ°API: {set(matches)}")

            print("\n" + "=" * 70)
            print("  æµè§ˆå™¨å°†ä¿æŒæ‰“å¼€30ç§’ï¼Œè¯·æ‰‹åŠ¨æŸ¥çœ‹é¡µé¢...")
            print("  æŸ¥çœ‹æ˜¯å¦æœ‰å†å²æ•°æ®ã€å›¾è¡¨ã€ç»Ÿè®¡ç­‰é“¾æ¥")
            print("=" * 70)

            page.wait_for_timeout(30000)  # ä¿æŒ30ç§’è®©ç”¨æˆ·æŸ¥çœ‹

            browser.close()

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    check_xtracker_history()
